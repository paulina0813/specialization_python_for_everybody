{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Following Links in Python**\n",
    "\n",
    "In this assignment you will write a Python program that expands on http://www.py4e.com/code3/urllinks.py. The program will use urllib to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position relative to the first name in the list, follow that link and repeat the process a number of times and report the last name you find.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the name for your testing and the other is the actual data you need to process for the assignment\n",
    "\n",
    "- Sample problem: Start at http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "Find the link at position 3 (the first name is 1). Follow that link. Repeat this process 4 times. The answer is the last name that you retrieve.\n",
    "Sequence of names: Fikret Montgomery Mhairade Butchi Anayah\n",
    "\n",
    "    Last name in sequence: Anayah\n",
    "    \n",
    "- Actual problem: Start at: http://py4e-data.dr-chuck.net/known_by_Maha.html\n",
    "Find the link at position 18 (the first name is 1). Follow that link. Repeat this process 7 times. The answer is the last name that you retrieve.\n",
    "Hint: The first character of the name of the last page that you will load is: T\n",
    "\n",
    "\n",
    "## **Strategy**\n",
    "The web pages tweak the height between the links and hide the page after a few seconds to make it difficult for you to do the assignment without writing a Python program. But frankly with a little effort and patience you can overcome these attempts to make it a little harder to complete the assignment without writing a Python program. But that is not the point. The point is to write a clever Python program to solve the program.\n",
    "\n",
    "\n",
    "## **Sample execution**\n",
    "Here is a sample execution of a solution:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ python3 solution.py\n",
    "Enter URL: http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "Enter count: 4\n",
    "Enter position: 3\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Montgomery.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Mhairade.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Butchi.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Anayah.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to the assignment for this execution is \"Anayah\".\n",
    "\n",
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "'''\n",
    "- Sample data: http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "    - Find the link at position 3 (the first name is 1). Follow that link. Repeat this process 4 times. The answer is the last name that you retrieve. Sequence of names: \n",
    "        Fikret Montgomery Mhairade Butchi Anayah \n",
    "- Actual data:  http://py4e-data.dr-chuck.net/known_by_Maha.html \n",
    "    - Find the link at position 18 (the first name is 1). Follow that link. Repeat this process 7 times. The answer is the last name that you retrieve.\n",
    "        Hint: The first character of the name of the last page that you will load is: T\n",
    "'''\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "count = int(input(\"Enter count: \"))\n",
    "position = int(input(\"Enter a position: \"))\n",
    "\n",
    "\n",
    "for i in range(1,count+1,1):\n",
    "    html = urllib.request.urlopen(url, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Retrieve all of the anchor tags\n",
    "    tags = soup('a')\n",
    "    iteration = 0\n",
    "    for tag in tags:\n",
    "    #print(tag.get('href', None))\n",
    "        iteration += 1\n",
    "        if iteration == position:\n",
    "            iteration = 0\n",
    "            new_url = tag.get('href', None)\n",
    "            url = new_url\n",
    "            print(new_url)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
